{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahliavayser/mahjong-scorer/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# ğŸ€„ Train YOLOv8 from Downloaded Dataset\n",
        "# ========================================\n",
        "#\n",
        "# You already downloaded a YOLOv8 dataset zip from Roboflow.\n",
        "# This script will train on it and export to TensorFlow.js.\n",
        "#\n",
        "# Run in Google Colab with GPU enabled!\n",
        "# ========================================\n",
        "\n",
        "print(\"ğŸ€„ YOLOv8 Training from Downloaded Dataset\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Step 1: Install dependencies\n",
        "print(\"\\nğŸ“¦ Step 1: Installing dependencies...\")\n",
        "!pip install -q ultralytics\n",
        "\n",
        "# Step 2: Upload your dataset zip\n",
        "print(\"\\nğŸ“¤ Step 2: Upload your dataset zip file...\")\n",
        "print(\"Click the 'Choose Files' button below and select your downloaded zip.\")\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded filename\n",
        "zip_filename = list(uploaded.keys())[0]\n",
        "print(f\"\\nâœ… Uploaded: {zip_filename}\")\n",
        "\n",
        "# Step 3: Extract the dataset\n",
        "print(\"\\nğŸ“‚ Step 3: Extracting dataset...\")\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('mahjong_dataset')\n",
        "\n",
        "print(\"âœ… Extracted!\")\n",
        "\n",
        "# Show contents\n",
        "print(\"\\nğŸ“ Dataset contents:\")\n",
        "!ls -la mahjong_dataset/\n",
        "!find mahjong_dataset -name \"*.yaml\" | head -5\n",
        "\n",
        "# Find the data.yaml file\n",
        "import glob\n",
        "yaml_files = glob.glob('mahjong_dataset/**/data.yaml', recursive=True)\n",
        "if not yaml_files:\n",
        "    yaml_files = glob.glob('mahjong_dataset/**/*.yaml', recursive=True)\n",
        "\n",
        "if yaml_files:\n",
        "    data_yaml_path = yaml_files[0]\n",
        "    print(f\"\\nâœ… Found config: {data_yaml_path}\")\n",
        "else:\n",
        "    # Try common locations\n",
        "    possible_paths = [\n",
        "        'mahjong_dataset/data.yaml',\n",
        "        'mahjong_dataset/dataset.yaml',\n",
        "    ]\n",
        "    for p in possible_paths:\n",
        "        if os.path.exists(p):\n",
        "            data_yaml_path = p\n",
        "            break\n",
        "    else:\n",
        "        print(\"âŒ Could not find data.yaml\")\n",
        "        print(\"Listing all files:\")\n",
        "        !find mahjong_dataset -type f | head -20\n",
        "        data_yaml_path = input(\"Enter the path to data.yaml: \").strip()\n",
        "\n",
        "# Show the yaml contents\n",
        "print(f\"\\nğŸ“‹ Dataset config ({data_yaml_path}):\")\n",
        "!cat {data_yaml_path}\n",
        "\n",
        "# Fix paths in data.yaml if needed (Roboflow sometimes uses absolute paths)\n",
        "print(\"\\nğŸ”§ Fixing dataset paths...\")\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    yaml_content = f.read()\n",
        "\n",
        "# Get the directory containing data.yaml\n",
        "dataset_dir = os.path.dirname(os.path.abspath(data_yaml_path))\n",
        "\n",
        "# Update the yaml to use relative paths\n",
        "import yaml\n",
        "\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    data_config = yaml.safe_load(f)\n",
        "\n",
        "# Fix the path to be the dataset directory\n",
        "data_config['path'] = dataset_dir\n",
        "\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f)\n",
        "\n",
        "print(\"âœ… Paths fixed!\")\n",
        "print(f\"Dataset path: {dataset_dir}\")\n",
        "\n",
        "# Count images\n",
        "print(\"\\nğŸ“· Counting training images...\")\n",
        "!find {dataset_dir} -name \"*.jpg\" -o -name \"*.png\" | wc -l\n",
        "\n",
        "# Step 4: Train YOLOv8\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸš€ Step 4: Training YOLOv8 model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 nano model\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train\n",
        "print(\"\\nğŸ‹ï¸ Starting training...\")\n",
        "print(\"This typically takes 30-60 minutes.\")\n",
        "\n",
        "results = model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=50,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    patience=15,\n",
        "    device=0,\n",
        "    project='mahjong_detector',\n",
        "    name='train',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"\\nâœ… Training complete!\")\n",
        "\n",
        "# Show results\n",
        "print(\"\\nğŸ“Š Training Results:\")\n",
        "print(f\"Best mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
        "\n",
        "# Step 5: Export to TensorFlow.js\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ”„ Step 5: Exporting to TensorFlow.js...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "best_model_path = 'mahjong_detector/train/weights/best.pt'\n",
        "trained_model = YOLO(best_model_path)\n",
        "\n",
        "# Export to TF.js\n",
        "trained_model.export(format='tfjs')\n",
        "print(\"âœ… Export complete!\")\n",
        "\n",
        "# Step 6: Package and download\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ“¦ Step 6: Packaging for download...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Find TF.js model\n",
        "tfjs_path = 'mahjong_detector/train/weights/best_web_model'\n",
        "if not os.path.exists(tfjs_path):\n",
        "    !find . -name \"*_web_model\" -type d\n",
        "    tfjs_path = input(\"Enter TF.js model path: \").strip()\n",
        "\n",
        "if os.path.exists(tfjs_path):\n",
        "    # Zip it\n",
        "    shutil.make_archive('mahjong_tfjs_model', 'zip', tfjs_path)\n",
        "\n",
        "    print(\"\\nğŸ“‚ Model contents:\")\n",
        "    !ls -la {tfjs_path}\n",
        "\n",
        "    # Download\n",
        "    files.download('mahjong_tfjs_model.zip')\n",
        "    print(\"\\nğŸ“¥ Downloading mahjong_tfjs_model.zip...\")\n",
        "\n",
        "    # Also download PyTorch model as backup\n",
        "    if os.path.exists(best_model_path):\n",
        "        files.download(best_model_path)\n",
        "        print(\"ğŸ“¥ Also downloading best.pt...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ‰ ALL DONE!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\"\"\n",
        "You should have downloaded:\n",
        "  âœ… mahjong_tfjs_model.zip - For browser use\n",
        "\n",
        "Next steps:\n",
        "1. Extract the zip file\n",
        "2. Copy contents to: mahjong-scorer/public/models/mahjong-detector/\n",
        "3. The app will use it automatically!\n",
        "\n",
        "ğŸ€„ Happy mahjong scoring!\n",
        "\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w_Qou6ozp0E9",
        "outputId": "15af1de1-a951-4cea-925c-dfb9c32d7a7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ€„ YOLOv8 Training from Downloaded Dataset\n",
            "============================================================\n",
            "\n",
            "ğŸ“¦ Step 1: Installing dependencies...\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\n",
            "ğŸ“¤ Step 2: Upload your dataset zip file...\n",
            "Click the 'Choose Files' button below and select your downloaded zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-565d668f-6610-4ace-bf74-56f33b25f21c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-565d668f-6610-4ace-bf74-56f33b25f21c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Mahjong.v83i.yolov8.zip to Mahjong.v83i.yolov8.zip\n",
            "\n",
            "âœ… Uploaded: Mahjong.v83i.yolov8.zip\n",
            "\n",
            "ğŸ“‚ Step 3: Extracting dataset...\n",
            "âœ… Extracted!\n",
            "\n",
            "ğŸ“ Dataset contents:\n",
            "total 32\n",
            "drwxr-xr-x 5 root root 4096 Dec 12 21:28 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 12 21:28 ..\n",
            "-rw-r--r-- 1 root root  508 Dec 12 21:28 data.yaml\n",
            "-rw-r--r-- 1 root root  189 Dec 12 21:28 README.dataset.txt\n",
            "-rw-r--r-- 1 root root 1309 Dec 12 21:28 README.roboflow.txt\n",
            "drwxr-xr-x 4 root root 4096 Dec 12 21:28 test\n",
            "drwxr-xr-x 4 root root 4096 Dec 12 21:28 train\n",
            "drwxr-xr-x 4 root root 4096 Dec 12 21:28 valid\n",
            "mahjong_dataset/data.yaml\n",
            "\n",
            "âœ… Found config: mahjong_dataset/data.yaml\n",
            "\n",
            "ğŸ“‹ Dataset config (mahjong_dataset/data.yaml):\n",
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 42\n",
            "names: ['1B', '1C', '1D', '1F', '1S', '2B', '2C', '2D', '2F', '2S', '3B', '3C', '3D', '3F', '3S', '4B', '4C', '4D', '4F', '4S', '5B', '5C', '5D', '6B', '6C', '6D', '7B', '7C', '7D', '8B', '8C', '8D', '9B', '9C', '9D', 'EW', 'GD', 'NW', 'RD', 'SW', 'WD', 'WW']\n",
            "\n",
            "roboflow:\n",
            "  workspace: jon-chan-gnsoa\n",
            "  project: mahjong-baq4s\n",
            "  version: 83\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/jon-chan-gnsoa/mahjong-baq4s/dataset/83\n",
            "ğŸ”§ Fixing dataset paths...\n",
            "âœ… Paths fixed!\n",
            "Dataset path: /content/mahjong_dataset\n",
            "\n",
            "ğŸ“· Counting training images...\n",
            "7650\n",
            "\n",
            "============================================================\n",
            "ğŸš€ Step 4: Training YOLOv8 model...\n",
            "============================================================\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 140.4MB/s 0.0s\n",
            "\n",
            "ğŸ‹ï¸ Starting training...\n",
            "This typically takes 30-60 minutes.\n",
            "Ultralytics 8.3.237 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=mahjong_dataset/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=mahjong_detector, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/mahjong_detector/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 23.3MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=42\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    759502  ultralytics.nn.modules.head.Detect           [42, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,019,038 parameters, 3,019,022 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 100.2MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2785.8Â±766.2 MB/s, size: 282.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/mahjong_dataset/train/labels... 6294 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 6294/6294 2.1Kit/s 3.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/mahjong_dataset/train/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 3316, len(boxes) = 98641. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 690.0Â±379.4 MB/s, size: 216.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/mahjong_dataset/valid/labels... 788 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 788/788 995.8it/s 0.8s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/mahjong_dataset/valid/images/396615245_1012553140002307_5358505426230168323_n_jpg.rf.a20076b647c5c5d13896be798ce11959.jpg: 27 duplicate labels removed\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/mahjong_dataset/valid/labels.cache\n",
            "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 110, len(boxes) = 9933. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/mahjong_detector/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000217, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/mahjong_detector/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      4.53G       1.59      4.132      1.184        115        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.6it/s 2:31\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 1.8it/s 13.8s\n",
            "                   all        788       9933        0.1      0.251      0.106     0.0687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      4.96G      1.374      2.603      1.085        247        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.7it/s 2:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 12.0s\n",
            "                   all        788       9933       0.38      0.465      0.419      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50       5.4G      1.303      2.053      1.068        111        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.7it/s 2:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.9s\n",
            "                   all        788       9933      0.535      0.614      0.583      0.415\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      5.41G      1.243      1.733      1.059        191        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.7it/s 2:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.7s\n",
            "                   all        788       9933      0.598      0.681      0.661      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      5.94G      1.207      1.543       1.05        135        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.7it/s 2:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.9s\n",
            "                   all        788       9933      0.689      0.711      0.727      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      5.96G       1.18      1.432      1.044        340        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 12.0s\n",
            "                   all        788       9933      0.736      0.721      0.768      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      5.98G      1.144      1.329      1.032        230        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.7s\n",
            "                   all        788       9933      0.772      0.763      0.806      0.592\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50         6G      1.143      1.281      1.028        166        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.3s\n",
            "                   all        788       9933      0.803      0.765      0.818      0.602\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      6.01G      1.125      1.219      1.026        232        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.4s\n",
            "                   all        788       9933      0.798      0.781      0.828       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      6.03G      1.114      1.188      1.023        132        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.8s\n",
            "                   all        788       9933      0.824      0.799      0.846      0.633\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      6.05G      1.101      1.161      1.015        149        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.8s\n",
            "                   all        788       9933      0.824      0.794       0.85      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      6.06G      1.086      1.105      1.009        226        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.8s\n",
            "                   all        788       9933      0.829       0.81      0.858      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      6.08G      1.079      1.096      1.007        147        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.2s\n",
            "                   all        788       9933      0.845      0.825      0.872      0.649\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50       6.1G      1.068      1.067      1.004        123        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.5s\n",
            "                   all        788       9933      0.853      0.818      0.871      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      6.12G      1.053       1.04     0.9987        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.7s\n",
            "                   all        788       9933      0.851      0.845      0.879      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      6.13G      1.053      1.031     0.9994        181        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.4s\n",
            "                   all        788       9933       0.86      0.824       0.88      0.654\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      6.15G      1.047      1.007     0.9932        108        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.7s\n",
            "                   all        788       9933      0.882       0.84      0.891      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      6.17G      1.036     0.9837      0.992        174        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.1s\n",
            "                   all        788       9933      0.878      0.838      0.891      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      6.79G      1.032      0.971     0.9952        141        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.2s\n",
            "                   all        788       9933      0.879      0.843      0.892      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      6.81G       1.02     0.9514     0.9844        235        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 11.0s\n",
            "                   all        788       9933      0.882       0.84      0.895      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      6.83G      1.015     0.9413     0.9835        147        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.3s\n",
            "                   all        788       9933      0.875      0.852      0.895      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      6.85G      1.009     0.9324     0.9842        132        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.4s\n",
            "                   all        788       9933      0.874      0.862      0.903      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      6.86G     0.9952      0.915     0.9773        109        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.7it/s 2:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 12.1s\n",
            "                   all        788       9933       0.89      0.857      0.903      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      6.88G     0.9967     0.9092      0.976        173        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 12.1s\n",
            "                   all        788       9933      0.903      0.853      0.908      0.687\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50       6.9G     0.9877     0.8979     0.9745        141        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.4s\n",
            "                   all        788       9933      0.897      0.856      0.908      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      6.91G     0.9978     0.8873     0.9757        164        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 12.0s\n",
            "                   all        788       9933      0.895      0.866      0.909      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      6.93G     0.9816      0.884     0.9732         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.5s\n",
            "                   all        788       9933      0.904      0.862      0.914      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      6.95G     0.9704     0.8645       0.97        229        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.8s\n",
            "                   all        788       9933      0.902      0.863      0.915      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      6.97G     0.9743     0.8598      0.968        294        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.7it/s 2:24\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 11.0s\n",
            "                   all        788       9933      0.902      0.866      0.918      0.701\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      6.98G     0.9692     0.8515     0.9669        174        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:23\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.3s\n",
            "                   all        788       9933      0.909      0.863      0.917      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50         7G     0.9598     0.8502     0.9665        156        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.2s\n",
            "                   all        788       9933      0.903      0.872      0.917      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      7.02G     0.9617     0.8404     0.9636        146        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 11.0s\n",
            "                   all        788       9933      0.906      0.869      0.916      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      7.03G     0.9483     0.8293     0.9596        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.3s\n",
            "                   all        788       9933      0.909      0.873       0.92      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      7.05G     0.9471     0.8249     0.9586        183        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.7s\n",
            "                   all        788       9933       0.91       0.87      0.917      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      7.07G     0.9413     0.8154     0.9577        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 11.0s\n",
            "                   all        788       9933      0.912      0.873      0.921      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      7.09G     0.9424     0.8083     0.9589        151        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:20\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.2s\n",
            "                   all        788       9933      0.903      0.882      0.923      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50       7.1G     0.9337     0.7999     0.9549        177        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.2s\n",
            "                   all        788       9933      0.922      0.871      0.924      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      7.12G     0.9284     0.7986     0.9531        143        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:19\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.4it/s 10.5s\n",
            "                   all        788       9933      0.909      0.888      0.926       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      7.14G     0.9322     0.7964     0.9537        146        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:21\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 11.1s\n",
            "                   all        788       9933      0.908      0.885      0.926      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      7.15G     0.9266     0.7899     0.9517        126        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.8it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.8s\n",
            "                   all        788       9933      0.912      0.878      0.924      0.711\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      7.17G     0.8955     0.6982     0.9522        104        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:18\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.8s\n",
            "                   all        788       9933      0.917      0.872      0.922      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      7.19G      0.873     0.6771     0.9434        128        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.4s\n",
            "                   all        788       9933      0.922      0.872      0.925       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      7.21G     0.8679     0.6732     0.9433         89        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.6s\n",
            "                   all        788       9933      0.917      0.879      0.926      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      7.22G      0.864      0.662     0.9402         76        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 10.9s\n",
            "                   all        788       9933      0.918      0.877      0.927      0.713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      7.24G     0.8554     0.6549     0.9361         64        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 11.7s\n",
            "                   all        788       9933      0.911      0.887      0.925      0.713\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      7.26G     0.8554     0.6547     0.9366         92        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 11.1s\n",
            "                   all        788       9933      0.916      0.881      0.926      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      7.27G     0.8484     0.6457     0.9332        195        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.4it/s 10.5s\n",
            "                   all        788       9933      0.918      0.883      0.926      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      7.29G     0.8481     0.6453     0.9347         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.3s\n",
            "                   all        788       9933       0.92      0.882      0.927      0.715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      7.31G     0.8451     0.6431     0.9323         78        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:15\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.2it/s 11.6s\n",
            "                   all        788       9933      0.917      0.884      0.928      0.716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      7.32G     0.8411       0.64     0.9308        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 394/394 2.9it/s 2:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.3it/s 11.0s\n",
            "                   all        788       9933      0.919      0.882      0.928      0.715\n",
            "\n",
            "50 epochs completed in 2.122 hours.\n",
            "Optimizer stripped from /content/mahjong_detector/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/mahjong_detector/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/mahjong_detector/train/weights/best.pt...\n",
            "Ultralytics 8.3.237 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,013,838 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 2.1it/s 12.1s\n",
            "                   all        788       9933      0.917      0.884      0.928      0.716\n",
            "                    1B        200        262      0.933      0.889      0.933       0.71\n",
            "                    1C        210        264      0.933      0.894      0.944      0.687\n",
            "                    1D        186        260      0.975      0.892       0.97      0.753\n",
            "                    1F         90         92      0.785      0.826      0.858      0.678\n",
            "                    1S         87         89      0.651      0.618      0.674      0.547\n",
            "                    2B        229        292      0.947      0.914      0.939      0.712\n",
            "                    2C        212        268       0.94      0.881      0.915      0.696\n",
            "                    2D        202        267      0.965      0.974      0.984      0.755\n",
            "                    2F         90         90      0.931      0.856      0.935      0.741\n",
            "                    2S         78         78      0.879      0.782      0.891      0.722\n",
            "                    3B        230        271       0.96      0.945      0.965      0.732\n",
            "                    3C        252        315      0.904      0.949      0.954      0.738\n",
            "                    3D        240        311       0.97      0.927       0.97      0.728\n",
            "                    3F         85         86      0.731      0.744      0.808      0.588\n",
            "                    3S         83         84       0.84      0.685      0.838       0.68\n",
            "                    4B        244        295      0.946      0.943      0.966      0.746\n",
            "                    4C        234        280      0.961      0.932      0.952      0.739\n",
            "                    4D        231        299      0.952      0.939      0.952      0.734\n",
            "                    4F         76         78      0.885      0.859      0.926      0.759\n",
            "                    4S         73         74      0.637      0.758       0.74      0.598\n",
            "                    5B        235        294      0.981      0.949      0.975      0.758\n",
            "                    5C        232        298      0.932      0.875      0.939      0.707\n",
            "                    5D        237        292      0.975      0.959      0.974      0.744\n",
            "                    6B        234        300       0.94      0.977      0.961      0.744\n",
            "                    6C        235        284      0.912      0.901       0.95       0.74\n",
            "                    6D        223        282      0.959      0.922      0.959      0.765\n",
            "                    7B        215        263      0.953      0.932      0.967       0.75\n",
            "                    7C        229        283      0.907      0.901      0.953      0.722\n",
            "                    7D        248        299      0.968      0.967      0.981      0.771\n",
            "                    8B        213        276      0.946      0.917      0.948      0.744\n",
            "                    8C        230        307      0.979      0.899      0.947      0.725\n",
            "                    8D        224        283      0.974      0.936      0.967      0.779\n",
            "                    9B        206        267      0.946       0.92      0.956      0.753\n",
            "                    9C        179        244      0.926      0.768      0.869      0.657\n",
            "                    9D        193        255      0.917      0.922      0.962      0.777\n",
            "                    EW        157        214      0.901      0.894      0.926        0.7\n",
            "                    GD        194        266      0.959      0.874      0.942      0.714\n",
            "                    NW        179        235      0.952      0.844       0.93      0.676\n",
            "                    RD        196        267      0.973      0.921      0.971      0.739\n",
            "                    SW        168        252      0.925      0.869      0.929      0.646\n",
            "                    WD        149        211      0.966        0.9      0.959      0.747\n",
            "                    WW        158        206      0.907      0.856      0.906      0.678\n",
            "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/mahjong_detector/train\u001b[0m\n",
            "\n",
            "âœ… Training complete!\n",
            "\n",
            "ğŸ“Š Training Results:\n",
            "Best mAP50: 0.9281243862179932\n",
            "\n",
            "============================================================\n",
            "ğŸ”„ Step 5: Exporting to TensorFlow.js...\n",
            "============================================================\n",
            "Ultralytics 8.3.237 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "Model summary (fused): 72 layers, 3,013,838 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'mahjong_detector/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 46, 8400) (5.9 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx>=1.12.0,<=1.19.1', 'onnx2tf>=1.26.3', 'onnxslim>=0.1.71', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 20 packages in 2.57s\n",
            "Prepared 11 packages in 13.49s\n",
            "Installed 11 packages in 350ms\n",
            " + ai-edge-litert==2.0.3\n",
            " + backports-strenum==1.3.1\n",
            " + colorama==0.4.6\n",
            " + coloredlogs==15.0.1\n",
            " + humanfriendly==10.0\n",
            " + onnx==1.19.1\n",
            " + onnx-graphsurgeon==0.5.8\n",
            " + onnx2tf==1.28.5\n",
            " + onnxruntime-gpu==1.23.2\n",
            " + onnxslim==0.1.78\n",
            " + sng4onnx==1.0.4\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 17.0s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.78...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.5s, saved as 'mahjong_detector/train/weights/best.onnx' (11.7 MB)\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 1.1MB 32.4MB/s 0.0s\n",
            "\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 41.6files/s 0.0s\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.5...\n",
            "Saved artifact at 'mahjong_detector/train/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 46, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138910701521616: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138910701522192: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  138910701522384: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  138910701526800: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138910701527184: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  138910701525648: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910701527376: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  138910701527568: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910701528528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701528144: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701530448: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  138910701531024: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  138910701527760: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  138910701524304: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  138910701529104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701528720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701531216: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  138910701531792: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910701530064: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138910701532176: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  138910701529872: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910701532368: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910701531984: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910701533328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701532560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701533712: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  138910701534672: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910701530640: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  138910701531408: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910701533904: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  138910701534864: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910701531600: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  138910701535056: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910701532752: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701533136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910701534096: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  138910710530320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710530704: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138910710530512: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n",
            "  138910710530128: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710531088: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  138910710531280: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710531856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710531664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710533776: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710533968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710531472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710530896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710533200: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710534160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710532816: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710534544: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710532048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710532240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710534928: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  138910710534352: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710535120: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138910710533392: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  138910710534736: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138910710535504: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  138910710535696: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138910710536272: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710536080: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710538192: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  138910710538384: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710535888: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  138910710535312: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710536464: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710536656: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710538576: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  138910710537232: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138910710537616: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  138910710538960: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710537808: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  138910710538768: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138910710539728: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  138910710539920: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710540304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710539536: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710541648: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710541840: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710540112: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710539152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710541072: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710539344: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710542608: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  138910710542416: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910710541264: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  138910710541456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710543184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710542992: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710545104: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  138910710545296: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910710542800: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  138910710540880: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  138910710543376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710543568: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910710545680: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  138910710545488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710545872: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138910710544528: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710544144: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695818640: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  138910695818064: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910695819792: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695819600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695822288: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695822480: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695821328: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695822864: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695820176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695820368: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695819984: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  138910695821904: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910695823056: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  138910695819216: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  138910695820944: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910695822672: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  138910695824208: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138910695825744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695825552: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695826128: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  138910695826896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910695828240: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  138910695828816: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  138910695826320: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695826704: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  138910695827856: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  138910695829008: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  138910695828624: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  138910695828048: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  138910695823440: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  138910695822096: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  138910710544720: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910710546256: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695824400: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695828432: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695823248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695823824: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695817296: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910710546064: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695829584: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695827472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695824592: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695821520: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695818256: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695817488: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695829200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695829392: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695823632: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695824016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695817872: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695817680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695830352: TensorSpec(shape=(1, 1, 64, 42), dtype=tf.float32, name=None)\n",
            "  138910695829776: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695825936: TensorSpec(shape=(1, 1, 64, 42), dtype=tf.float32, name=None)\n",
            "  138910695825168: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695819408: TensorSpec(shape=(1, 1, 64, 42), dtype=tf.float32, name=None)\n",
            "  138910695819024: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  138910695830160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695829968: TensorSpec(shape=(42,), dtype=tf.float32, name=None)\n",
            "  138910695824976: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695824784: TensorSpec(shape=(42,), dtype=tf.float32, name=None)\n",
            "  138910695818448: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  138910695818832: TensorSpec(shape=(42,), dtype=tf.float32, name=None)\n",
            "  138910695832656: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  138910695827088: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  138910695832464: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  138910695831312: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  138910695831120: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  138910695832272: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  138910695831504: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 41.5s, saved as 'mahjong_detector/train/weights/best_saved_model' (29.3 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success âœ… 1.4s, saved as 'mahjong_detector/train/weights/best.pb' (11.7 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorflowjs'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 68 packages in 473ms\n",
            "Prepared 2 packages in 27ms\n",
            "Uninstalled 1 package in 2ms\n",
            "Installed 2 packages in 3ms\n",
            " - packaging==25.0\n",
            " + packaging==23.2\n",
            " + tensorflowjs==4.22.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 0.7s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"margin:0px;\">ğŸŒ² Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
              "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
              "        Decision Forests</a> using the same algorithms but with more features and faster\n",
              "    training!\n",
              "</p>\n",
              "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            Old code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import tensorflow_decision_forests as tfdf\n",
              "\n",
              "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
              "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
              "model.fit(tf_ds)\n",
              "</pre>\n",
              "    </div>\n",
              "    <div style=\"width: 5px;\"></div>\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            New code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import ydf\n",
              "\n",
              "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
              "</pre>\n",
              "    </div>\n",
              "</div>\n",
              "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
              "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
              "        guide</a>)</p>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m starting export with tensorflowjs 4.22.0...\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m output node names: Identity:0\n",
            "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m running 'tensorflowjs_converter --input_format=tf_frozen_model  --output_node_names=Identity:0 \"mahjong_detector/train/weights/best.pb\" \"mahjong_detector/train/weights/best_web_model\"'\n",
            "\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m export success âœ… 10.0s, saved as 'mahjong_detector/train/weights/best_web_model' (11.8 MB)\n",
            "\n",
            "Export complete (53.3s)\n",
            "Results saved to \u001b[1m/content/mahjong_detector/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=mahjong_detector/train/weights/best_web_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=mahjong_detector/train/weights/best_web_model imgsz=640 data=mahjong_dataset/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "âœ… Export complete!\n",
            "\n",
            "============================================================\n",
            "ğŸ“¦ Step 6: Packaging for download...\n",
            "============================================================\n",
            "\n",
            "ğŸ“‚ Model contents:\n",
            "total 12108\n",
            "drwxr-xr-x 2 root root    4096 Dec 12 23:37 .\n",
            "drwxr-xr-x 4 root root    4096 Dec 12 23:37 ..\n",
            "-rw-r--r-- 1 root root 4194304 Dec 12 23:37 group1-shard1of3.bin\n",
            "-rw-r--r-- 1 root root 4194304 Dec 12 23:37 group1-shard2of3.bin\n",
            "-rw-r--r-- 1 root root 3836136 Dec 12 23:37 group1-shard3of3.bin\n",
            "-rw-r--r-- 1 root root     737 Dec 12 23:37 metadata.yaml\n",
            "-rw-r--r-- 1 root root  156665 Dec 12 23:37 model.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9261015e-f8e3-4fe9-a899-9c671c988015\", \"mahjong_tfjs_model.zip\", 11187596)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¥ Downloading mahjong_tfjs_model.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b106790c-168e-47c5-a9b5-5eedc1c1a202\", \"best.pt\", 6215146)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¥ Also downloading best.pt...\n",
            "\n",
            "============================================================\n",
            "ğŸ‰ ALL DONE!\n",
            "============================================================\n",
            "\n",
            "You should have downloaded:\n",
            "  âœ… mahjong_tfjs_model.zip - For browser use\n",
            "\n",
            "Next steps:\n",
            "1. Extract the zip file\n",
            "2. Copy contents to: mahjong-scorer/public/models/mahjong-detector/\n",
            "3. The app will use it automatically!\n",
            "\n",
            "ğŸ€„ Happy mahjong scoring!\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}